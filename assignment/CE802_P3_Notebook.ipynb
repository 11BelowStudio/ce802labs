{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List, TypeVar, Dict, Any, Union"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE YOU WILL WRITE CODE TO TEST A NUMBER OF PREDICTORS\n",
    "# AND FINALLY CHOOSE AND TRAIN THE PREDICTOR THAT YOU WILL BE USING FOR PART B"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initially prodding the data to find out about it\n",
    "\n",
    "Once again, the lack of any feature names is particularly unhelpful."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       F1      F2      F3     F4       F5     F6        F7     F8       F9  \\\n0  271.78  -21.92      UK -10.80  1899.57  17.98 -21749.82  91.94   855.61   \n1  202.54   43.82     USA -16.94  1941.57  -9.16 -27668.04  93.50   975.44   \n2  220.26   88.90  Europe -18.76  2298.12 -18.38 -11548.56  65.16  1114.28   \n3  141.00  140.72  Europe -19.86  -133.32 -57.00 -16200.96 -14.00   910.12   \n4  165.04    2.74  Europe -21.34  3077.07 -20.50 -25683.06  29.08   216.24   \n\n     F10  ...      F28     F29       F30   F31     F32     F33     F34  \\\n0  10.01  ...  2098.80  500.16  -6325.53  1.36  -33.14  177.34 -141.97   \n1   7.29  ...  1668.70  434.97  -6172.05  2.59  -58.87   87.48 -154.11   \n2  12.05  ...  2604.56  252.93 -10132.68  2.94  -40.89  271.00 -279.84   \n3   4.54  ...  2595.56  154.83  -7862.04  0.86 -117.03  201.66 -153.93   \n4  10.10  ...  1066.80  316.68  -6093.81  3.59  -63.84  211.82 -182.34   \n\n      F35  F36   Target  \n0  101.52    5   189.03  \n1  623.22    6   187.17  \n2  284.96    2  1016.24  \n3  532.19    4  -141.18  \n4  373.14    5    33.17  \n\n[5 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F1</th>\n      <th>F2</th>\n      <th>F3</th>\n      <th>F4</th>\n      <th>F5</th>\n      <th>F6</th>\n      <th>F7</th>\n      <th>F8</th>\n      <th>F9</th>\n      <th>F10</th>\n      <th>...</th>\n      <th>F28</th>\n      <th>F29</th>\n      <th>F30</th>\n      <th>F31</th>\n      <th>F32</th>\n      <th>F33</th>\n      <th>F34</th>\n      <th>F35</th>\n      <th>F36</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>271.78</td>\n      <td>-21.92</td>\n      <td>UK</td>\n      <td>-10.80</td>\n      <td>1899.57</td>\n      <td>17.98</td>\n      <td>-21749.82</td>\n      <td>91.94</td>\n      <td>855.61</td>\n      <td>10.01</td>\n      <td>...</td>\n      <td>2098.80</td>\n      <td>500.16</td>\n      <td>-6325.53</td>\n      <td>1.36</td>\n      <td>-33.14</td>\n      <td>177.34</td>\n      <td>-141.97</td>\n      <td>101.52</td>\n      <td>5</td>\n      <td>189.03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202.54</td>\n      <td>43.82</td>\n      <td>USA</td>\n      <td>-16.94</td>\n      <td>1941.57</td>\n      <td>-9.16</td>\n      <td>-27668.04</td>\n      <td>93.50</td>\n      <td>975.44</td>\n      <td>7.29</td>\n      <td>...</td>\n      <td>1668.70</td>\n      <td>434.97</td>\n      <td>-6172.05</td>\n      <td>2.59</td>\n      <td>-58.87</td>\n      <td>87.48</td>\n      <td>-154.11</td>\n      <td>623.22</td>\n      <td>6</td>\n      <td>187.17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>220.26</td>\n      <td>88.90</td>\n      <td>Europe</td>\n      <td>-18.76</td>\n      <td>2298.12</td>\n      <td>-18.38</td>\n      <td>-11548.56</td>\n      <td>65.16</td>\n      <td>1114.28</td>\n      <td>12.05</td>\n      <td>...</td>\n      <td>2604.56</td>\n      <td>252.93</td>\n      <td>-10132.68</td>\n      <td>2.94</td>\n      <td>-40.89</td>\n      <td>271.00</td>\n      <td>-279.84</td>\n      <td>284.96</td>\n      <td>2</td>\n      <td>1016.24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>141.00</td>\n      <td>140.72</td>\n      <td>Europe</td>\n      <td>-19.86</td>\n      <td>-133.32</td>\n      <td>-57.00</td>\n      <td>-16200.96</td>\n      <td>-14.00</td>\n      <td>910.12</td>\n      <td>4.54</td>\n      <td>...</td>\n      <td>2595.56</td>\n      <td>154.83</td>\n      <td>-7862.04</td>\n      <td>0.86</td>\n      <td>-117.03</td>\n      <td>201.66</td>\n      <td>-153.93</td>\n      <td>532.19</td>\n      <td>4</td>\n      <td>-141.18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>165.04</td>\n      <td>2.74</td>\n      <td>Europe</td>\n      <td>-21.34</td>\n      <td>3077.07</td>\n      <td>-20.50</td>\n      <td>-25683.06</td>\n      <td>29.08</td>\n      <td>216.24</td>\n      <td>10.10</td>\n      <td>...</td>\n      <td>1066.80</td>\n      <td>316.68</td>\n      <td>-6093.81</td>\n      <td>3.59</td>\n      <td>-63.84</td>\n      <td>211.82</td>\n      <td>-182.34</td>\n      <td>373.14</td>\n      <td>5</td>\n      <td>33.17</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_all_data: pd.DataFrame = pd.read_csv(\"CE802_P3_Data.csv\")\n",
    "_all_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "F1        float64\nF2        float64\nF3         object\nF4        float64\nF5        float64\nF6        float64\nF7        float64\nF8        float64\nF9        float64\nF10       float64\nF11        object\nF12       float64\nF13       float64\nF14       float64\nF15       float64\nF16       float64\nF17       float64\nF18       float64\nF19       float64\nF20       float64\nF21       float64\nF22       float64\nF23         int64\nF24       float64\nF25       float64\nF26       float64\nF27       float64\nF28       float64\nF29       float64\nF30       float64\nF31       float64\nF32       float64\nF33       float64\nF34       float64\nF35       float64\nF36         int64\nTarget    float64\ndtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_all_data.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "_all_data_inputs: pd.DataFrame = _all_data.loc[:,_all_data.columns!=\"Target\"]\n",
    "_all_data_targets:pd.DataFrame = _all_data.loc[:,\"Target\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like I'll need to convert F3 and F11 into a less awkward format.\n",
    "Of course, there's the simple approach of doing one-hot encoding, but..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UK' 'USA' 'Europe' 'Rest']\n",
      "['Very low' 'Medium' 'Low' 'Very high' 'High']\n"
     ]
    }
   ],
   "source": [
    "print(_all_data_inputs[\"F3\"].unique())\n",
    "\n",
    "print(_all_data_inputs[\"F11\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As F11 indicates values with some sequential nature to them\n",
    "(very low->low->medium->high->very high), I could get away with converting them\n",
    "to ints. Which is what I am going to do.\n",
    "\n",
    "However, for F3, I should probably just replace them with some one-hot encoding instead.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "f11categories = CategoricalDtype(categories=[\"Very low\",\"Low\",\"Medium\",\"High\",\"Very high\"], ordered=True)\n",
    "\n",
    "f3categories = CategoricalDtype(categories=[\"Europe\",\"Rest\",\"UK\",\"USA\"])\n",
    "\n",
    "def df_f11_and_f3_to_sensible(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    f11dict = { \"F11\": {\n",
    "        \"Very low\": 0,\n",
    "        \"Low\": 1,\n",
    "        \"Medium\": 2,\n",
    "        \"High\": 3,\n",
    "        \"Very high\": 4\n",
    "    }}\n",
    "\n",
    "    df.replace(f11dict, inplace=True)\n",
    "\n",
    "    df = pd.get_dummies(df, columns=[\"F3\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "all_data = df_f11_and_f3_to_sensible(pd.read_csv(\"CE802_P3_Data.csv\"))\n",
    "\n",
    "_all_data_inputs = df_f11_and_f3_to_sensible(_all_data_inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1           float64\n",
      "F2           float64\n",
      "F4           float64\n",
      "F5           float64\n",
      "F6           float64\n",
      "F7           float64\n",
      "F8           float64\n",
      "F9           float64\n",
      "F10          float64\n",
      "F11            int64\n",
      "F12          float64\n",
      "F13          float64\n",
      "F14          float64\n",
      "F15          float64\n",
      "F16          float64\n",
      "F17          float64\n",
      "F18          float64\n",
      "F19          float64\n",
      "F20          float64\n",
      "F21          float64\n",
      "F22          float64\n",
      "F23            int64\n",
      "F24          float64\n",
      "F25          float64\n",
      "F26          float64\n",
      "F27          float64\n",
      "F28          float64\n",
      "F29          float64\n",
      "F30          float64\n",
      "F31          float64\n",
      "F32          float64\n",
      "F33          float64\n",
      "F34          float64\n",
      "F35          float64\n",
      "F36            int64\n",
      "F3_Europe      uint8\n",
      "F3_Rest        uint8\n",
      "F3_UK          uint8\n",
      "F3_USA         uint8\n",
      "dtype: object\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "       F1      F2     F4       F5     F6        F7     F8       F9    F10  \\\n0  271.78  -21.92 -10.80  1899.57  17.98 -21749.82  91.94   855.61  10.01   \n1  202.54   43.82 -16.94  1941.57  -9.16 -27668.04  93.50   975.44   7.29   \n2  220.26   88.90 -18.76  2298.12 -18.38 -11548.56  65.16  1114.28  12.05   \n3  141.00  140.72 -19.86  -133.32 -57.00 -16200.96 -14.00   910.12   4.54   \n4  165.04    2.74 -21.34  3077.07 -20.50 -25683.06  29.08   216.24  10.10   \n\n   F11  ...   F31     F32     F33     F34     F35  F36  F3_Europe  F3_Rest  \\\n0    0  ...  1.36  -33.14  177.34 -141.97  101.52    5          0        0   \n1    2  ...  2.59  -58.87   87.48 -154.11  623.22    6          0        0   \n2    2  ...  2.94  -40.89  271.00 -279.84  284.96    2          1        0   \n3    1  ...  0.86 -117.03  201.66 -153.93  532.19    4          1        0   \n4    0  ...  3.59  -63.84  211.82 -182.34  373.14    5          1        0   \n\n   F3_UK  F3_USA  \n0      1       0  \n1      0       1  \n2      0       0  \n3      0       0  \n4      0       0  \n\n[5 rows x 39 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F1</th>\n      <th>F2</th>\n      <th>F4</th>\n      <th>F5</th>\n      <th>F6</th>\n      <th>F7</th>\n      <th>F8</th>\n      <th>F9</th>\n      <th>F10</th>\n      <th>F11</th>\n      <th>...</th>\n      <th>F31</th>\n      <th>F32</th>\n      <th>F33</th>\n      <th>F34</th>\n      <th>F35</th>\n      <th>F36</th>\n      <th>F3_Europe</th>\n      <th>F3_Rest</th>\n      <th>F3_UK</th>\n      <th>F3_USA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>271.78</td>\n      <td>-21.92</td>\n      <td>-10.80</td>\n      <td>1899.57</td>\n      <td>17.98</td>\n      <td>-21749.82</td>\n      <td>91.94</td>\n      <td>855.61</td>\n      <td>10.01</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.36</td>\n      <td>-33.14</td>\n      <td>177.34</td>\n      <td>-141.97</td>\n      <td>101.52</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202.54</td>\n      <td>43.82</td>\n      <td>-16.94</td>\n      <td>1941.57</td>\n      <td>-9.16</td>\n      <td>-27668.04</td>\n      <td>93.50</td>\n      <td>975.44</td>\n      <td>7.29</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2.59</td>\n      <td>-58.87</td>\n      <td>87.48</td>\n      <td>-154.11</td>\n      <td>623.22</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>220.26</td>\n      <td>88.90</td>\n      <td>-18.76</td>\n      <td>2298.12</td>\n      <td>-18.38</td>\n      <td>-11548.56</td>\n      <td>65.16</td>\n      <td>1114.28</td>\n      <td>12.05</td>\n      <td>2</td>\n      <td>...</td>\n      <td>2.94</td>\n      <td>-40.89</td>\n      <td>271.00</td>\n      <td>-279.84</td>\n      <td>284.96</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>141.00</td>\n      <td>140.72</td>\n      <td>-19.86</td>\n      <td>-133.32</td>\n      <td>-57.00</td>\n      <td>-16200.96</td>\n      <td>-14.00</td>\n      <td>910.12</td>\n      <td>4.54</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.86</td>\n      <td>-117.03</td>\n      <td>201.66</td>\n      <td>-153.93</td>\n      <td>532.19</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>165.04</td>\n      <td>2.74</td>\n      <td>-21.34</td>\n      <td>3077.07</td>\n      <td>-20.50</td>\n      <td>-25683.06</td>\n      <td>29.08</td>\n      <td>216.24</td>\n      <td>10.10</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3.59</td>\n      <td>-63.84</td>\n      <td>211.82</td>\n      <td>-182.34</td>\n      <td>373.14</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(_all_data_inputs.dtypes)\n",
    "print(\"\")\n",
    "_all_data_inputs.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Much better.\n",
    "\n",
    "Anyway, here's a helper function that'll be useful later on,\n",
    "pretty much wrapping that dataframe reading/splitting/reformatting into a nice\n",
    "and simple function for ease of use later on."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def np_data_and_targets(df: pd.DataFrame = pd.read_csv(\"CE802_P3_Data.csv\"), already_formatted_f11_f3: bool = False, targetname: str = \"Target\") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Converts dataframe into a couple of numpy ndarrays for the data without the labels,\n",
    "    and the labels by themselves.\n",
    "    Also handles the f11 and f3 formatting.\n",
    "    :param df: the Dataframe\n",
    "    :param already_formatted_f11_f3: set this to true if we've already replaced f11 and f3 with sensible formatting.\n",
    "    :param targetname: The name of the column holding the targets\n",
    "    :return: tuple of [ndarray of the values without the targets, just the class labels]\n",
    "    \"\"\"\n",
    "\n",
    "    inputs:  np.ndarray = df.loc[:,df.columns != targetname].to_numpy() if already_formatted_f11_f3 else df_f11_and_f3_to_sensible(df.loc[:,df.columns != targetname]).to_numpy()\n",
    "    outputs: np.ndarray =  df.loc[:,targetname].to_numpy()\n",
    "\n",
    "    return inputs, outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting up a hold-out validation set for later"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "        F1      F2     F4       F5     F6        F7      F8      F9    F10  \\\n",
      "4   165.04    2.74 -21.34  3077.07 -20.50 -25683.06   29.08  216.24  10.10   \n",
      "6   166.76  -31.92 -27.18  1580.46 -58.42 -27216.24   31.98  468.47  11.86   \n",
      "8   200.42 -239.82 -19.46  2030.43 -12.30 -27179.04   65.72  203.12   1.25   \n",
      "17  138.02   19.76 -25.06  1001.61 -55.62 -24831.81   61.38  922.19   3.38   \n",
      "23  198.28   75.28  -7.04  2222.43  17.38 -12962.31  142.00  639.36   8.79   \n",
      "\n",
      "    F11  ...    F32     F33     F34     F35  F36   Target  F3_Europe  F3_Rest  \\\n",
      "4     0  ... -63.84  211.82 -182.34  373.14    5    33.17          1        0   \n",
      "6     2  ...   1.74  209.94 -161.74  809.57    2   339.31          0        1   \n",
      "8     4  ... -26.61  232.64 -196.92  825.80    3  1175.20          0        0   \n",
      "17    2  ... -54.34  150.76 -176.09  774.41    5  2152.67          0        1   \n",
      "23    1  ...  16.31  154.02 -256.52  214.32    8  -377.46          0        0   \n",
      "\n",
      "    F3_UK  F3_USA  \n",
      "4       0       0  \n",
      "6       0       0  \n",
      "8       1       0  \n",
      "17      0       0  \n",
      "23      1       0  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "(300, 40)\n",
      "train\n",
      "       F1      F2     F4       F5      F6        F7     F8       F9    F10  \\\n",
      "0  271.78  -21.92 -10.80  1899.57   17.98 -21749.82  91.94   855.61  10.01   \n",
      "1  202.54   43.82 -16.94  1941.57   -9.16 -27668.04  93.50   975.44   7.29   \n",
      "2  220.26   88.90 -18.76  2298.12  -18.38 -11548.56  65.16  1114.28  12.05   \n",
      "3  141.00  140.72 -19.86  -133.32  -57.00 -16200.96 -14.00   910.12   4.54   \n",
      "5  247.64   26.68 -30.24  1868.22 -121.16 -10192.29  -9.68   428.42   9.07   \n",
      "\n",
      "   F11  ...     F32     F33     F34     F35  F36   Target  F3_Europe  F3_Rest  \\\n",
      "0    0  ...  -33.14  177.34 -141.97  101.52    5   189.03          0        0   \n",
      "1    2  ...  -58.87   87.48 -154.11  623.22    6   187.17          0        0   \n",
      "2    2  ...  -40.89  271.00 -279.84  284.96    2  1016.24          1        0   \n",
      "3    1  ... -117.03  201.66 -153.93  532.19    4  -141.18          1        0   \n",
      "5    2  ... -132.50  223.08 -244.28  459.16    5   277.33          0        1   \n",
      "\n",
      "   F3_UK  F3_USA  \n",
      "0      1       0  \n",
      "1      0       1  \n",
      "2      0       0  \n",
      "3      0       0  \n",
      "5      0       0  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "(1200, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "validation_cv: KFold = KFold(n_splits=5, shuffle=True)\n",
    "all_train_indices, validation_indices = [i for i in validation_cv.split(_all_data_inputs, _all_data_targets)][0]\n",
    "\n",
    "validation_df: pd.DataFrame = all_data.iloc[validation_indices]\n",
    "tests: Tuple[np.ndarray, np.ndarray] = np_data_and_targets(validation_df, True)\n",
    "test_data: np.ndarray = tests[0]\n",
    "test_labels: np.ndarray = tests[1]\n",
    "\n",
    "train_df: pd.DataFrame = all_data.iloc[all_train_indices]\n",
    "trains: Tuple[np.ndarray, np.ndarray] = np_data_and_targets(train_df, True)\n",
    "train_data: np.ndarray = trains[0]\n",
    "train_labels: np.ndarray = trains[1]\n",
    "\n",
    "print(\"validation\")\n",
    "print(validation_df.head())\n",
    "print(validation_df.shape)\n",
    "print(\"train\")\n",
    "print(train_df.head())\n",
    "print(train_df.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting up some grid-search nested cross validation pipelines\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "R = TypeVar('R', bound=RegressorMixin)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def h_grid_searcher(\n",
    "        regressor: R,\n",
    "        param_grid: Dict[str, List[Any]],\n",
    "        train_data: np.ndarray,\n",
    "        train_targets: np.ndarray,\n",
    "        k_fold: KFold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    ") -> HalvingGridSearchCV:\n",
    "\n",
    "    param_grid[\"imputer__weights\"] = [\"distance\",\"uniform\"]\n",
    "    param_grid[\"poly__degree\"] = [2,3]\n",
    "\n",
    "    pl: Pipeline = Pipeline([\n",
    "        (\"imputer\",KNNImputer(add_indicator=True)),\n",
    "        (\"poly\", PolynomialFeatures(interaction_only=True)),\n",
    "        (\"regressor\",regressor)\n",
    "    ])\n",
    "\n",
    "    h_grid_search: HalvingGridSearchCV = HalvingGridSearchCV(\n",
    "        estimator=pl,\n",
    "        param_grid=param_grid,\n",
    "        factor=3,\n",
    "        cv=k_fold,\n",
    "        scoring=make_scorer(mean_squared_error),\n",
    "        refit=True,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    h_grid_search.fit(train_data, train_targets)\n",
    "\n",
    "    return h_grid_search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def nested_h_grid_searcher(\n",
    "        regressor: R,\n",
    "        param_grid: Dict[str, List[Any]],\n",
    "        train_data: np.ndarray,\n",
    "        train_targets: np.ndarray,\n",
    "        t_df: pd.DataFrame,\n",
    "        kfold_splits: int = 6\n",
    ") -> Dict[HalvingGridSearchCV, float]:\n",
    "\n",
    "    h_grid_search_dicts: Dict[HalvingGridSearchCV, float] = {}\n",
    "\n",
    "    kf: KFold = KFold(n_splits=kfold_splits, shuffle=True)\n",
    "\n",
    "    for train_indices, test_indices in kf.split(train_data, train_targets):\n",
    "        tr: Tuple[np.ndarray, np.ndarray] = np_data_and_targets(t_df.iloc[train_indices],True)\n",
    "        te: Tuple[np.ndarray, np.ndarray] = np_data_and_targets(t_df.iloc[test_indices],True)\n",
    "\n",
    "        current_search: HalvingGridSearchCV = h_grid_searcher(\n",
    "            regressor,\n",
    "            param_grid,\n",
    "            tr[0],\n",
    "            tr[1],\n",
    "            KFold(n_splits=kfold_splits-1, shuffle=False)\n",
    "        )\n",
    "\n",
    "        current_score: float = current_search.score(te[0],te[1])\n",
    "\n",
    "        h_grid_search_dicts[current_search] = current_score\n",
    "\n",
    "    return h_grid_search_dicts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regression\n",
    "\n",
    "There isn't much that I can do in terms of hyper-parameter search for simple linear regression,\n",
    "but, here goes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 333\n",
      "max_resources_: 1000\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 4\n",
      "n_resources: 333\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 999\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 333\n",
      "max_resources_: 1000\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 4\n",
      "n_resources: 333\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 999\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 333\n",
      "max_resources_: 1000\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 4\n",
      "n_resources: 333\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 999\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression_searched_dict: Dict[\n",
    "    HalvingGridSearchCV, float\n",
    "] = nested_h_grid_searcher(\n",
    "    LinearRegression(),\n",
    "    {},\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    train_df\n",
    ")\n",
    "\n",
    "linreg_searched: HalvingGridSearchCV = min(\n",
    "    linear_regression_searched_dict.keys(), key=lambda k: linear_regression_searched_dict[k]\n",
    ")\n",
    "\n",
    "best_linreg: Tuple[HalvingGridSearchCV, float] = (\n",
    "    linreg_searched, linear_regression_searched_dict[linreg_searched]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(best_linreg)\n",
    "\n",
    "print(best_linreg[1])\n",
    "\n",
    "linreg_searched.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Sample Consensus regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "rs_samples: List[int] = [1,2,3,4,5]\n",
    "rs_residuals: List[Union[float, None]] = [None, 0.001, 0.01, 0.1, 1]\n",
    "rs_max_trials: List[int] = [80,90,100,110,120]\n",
    "\n",
    "rs_param_dict: Dict[str, List[Any]] = {\n",
    "    \"regressor__min_samples\": rs_samples,\n",
    "    \"regressor__residual_threshold\": rs_residuals,\n",
    "    \"regressor__max_trials\": rs_max_trials\n",
    "}\n",
    "\n",
    "ransac_regression_searched_dict: Dict[\n",
    "    HalvingGridSearchCV, float\n",
    "] = nested_h_grid_searcher(\n",
    "    RANSACRegressor(loss=\"squared_error\"),\n",
    "    rs_param_dict,\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    train_df\n",
    ")\n",
    "\n",
    "ransac_searched: HalvingGridSearchCV = min(\n",
    "    ransac_regression_searched_dict.keys(), key=lambda k: ransac_regression_searched_dict[k]\n",
    ")\n",
    "\n",
    "best_ransac: Tuple[HalvingGridSearchCV, float] = (\n",
    "    ransac_searched, ransac_regression_searched_dict[ransac_searched]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(best_ransac)\n",
    "\n",
    "print(best_ransac[1])\n",
    "\n",
    "ransac_searched.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stochastic Gradient Descent Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE YOU WILL USE THIS TEMPLATE TO SAVE THE PREDICTIONS ON THE TEST SET\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('CE802_P3_Test.csv')\n",
    "\n",
    "final_data, final_targets = np_data_and_targets(pd.read_csv(\"CE802_P3_Test.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "predicted = linreg_searched.predict(final_data)\n",
    "# CHANGE HERE -- use your previously trained predictor and apply it to test_data\n",
    "# (test_data can be modified if needed but make sure you don't change the order of the rows)...\n",
    "\n",
    "# Replace the last (empty) column with your prediction\n",
    "test_df.iloc[:,-1] = predicted\n",
    "\n",
    "\n",
    "\n",
    "# Save to the destination file\n",
    "test_df.to_csv('CE802_P3_Test_Predictions.csv', index=False, float_format='%.8g')\n",
    "\n",
    "# IMPORTANT!! Make sure only the last column has changed\n",
    "assert pd.read_csv('CE802_P3_Test.csv').iloc[:,:-1].equals(pd.read_csv('CE802_P3_Test_Predictions.csv').iloc[:,:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}