{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the lizard problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: Jacobo Fernández-Vargas and Luca Citi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to solve from beginning to end the problem that was left as\n",
    "exercise in the second lab.\n",
    "\n",
    "This will allow us to go through all the steps involved in creating and testing\n",
    "a machine learning model.\n",
    "\n",
    "It is important to know that this dataset was not intended to use for\n",
    "classifications purposes, so we may not get good results or it may be a trivial problem.\n",
    "\n",
    "Regardless, this example will serve its purpose of seeing an example of building a\n",
    "pipeline from start to end. We will also point to some common errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "The data comes from a paper [1] that aimed at finding differences\n",
    "in the behaviour of lizards depending on the colour of their abdomen\n",
    "(yellow, white or orange).\n",
    "\n",
    "For example the authors wanted to know if lizards of a specific colour\n",
    "have bigger territories. Each sample is one observation of a specific lizard.\n",
    "\n",
    "The authors of the paper could not find any differences.\n",
    "We are going to use the dataset in a different way\n",
    "(i.e. predicting the colour of a lizard observed at a specific location at a given time).\n",
    "\n",
    "[1] https://onlinelibrary.wiley.com/doi/10.1002/ece3.6659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that the data is not ready to use in numpy,\n",
    "we use pandas to load the data and preprocess it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      ID_e         E         N Sex       Date   Hour Cell Label\n0     e1f1  5.583066  1.175189   f  05/6/2018  12:27   e1     o\n1     e1f1  5.325020  0.962680   f  21/6/2018  10:20   e1     o\n2     e1f1  3.412439  0.947501   f  21/6/2018  14:25   e1     o\n3     e1f1  3.761561  2.010046   f  21/6/2018  12:30   e1     o\n4     e1f1       NaN  1.144831   f  15/6/2018  12:06   e1     o\n...    ...       ...       ...  ..        ...    ...  ...   ...\n7184  e9m9  1.103858       NaN   m  25/5/2018  15:40   e9     y\n7185  e9m9  3.699470       NaN   m  25/5/2018  17:21   e9     y\n7186  e9m9  1.766447       NaN   m  24/5/2018  16:26   e9     y\n7187  e9m9  0.497900  1.169597   m  23/5/2018  12:30   e9     y\n7188  e9m9  3.990179  1.146944   m  23/5/2018  13:44   e9     y\n\n[7189 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_e</th>\n      <th>E</th>\n      <th>N</th>\n      <th>Sex</th>\n      <th>Date</th>\n      <th>Hour</th>\n      <th>Cell</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e1f1</td>\n      <td>5.583066</td>\n      <td>1.175189</td>\n      <td>f</td>\n      <td>05/6/2018</td>\n      <td>12:27</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e1f1</td>\n      <td>5.325020</td>\n      <td>0.962680</td>\n      <td>f</td>\n      <td>21/6/2018</td>\n      <td>10:20</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e1f1</td>\n      <td>3.412439</td>\n      <td>0.947501</td>\n      <td>f</td>\n      <td>21/6/2018</td>\n      <td>14:25</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e1f1</td>\n      <td>3.761561</td>\n      <td>2.010046</td>\n      <td>f</td>\n      <td>21/6/2018</td>\n      <td>12:30</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e1f1</td>\n      <td>NaN</td>\n      <td>1.144831</td>\n      <td>f</td>\n      <td>15/6/2018</td>\n      <td>12:06</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7184</th>\n      <td>e9m9</td>\n      <td>1.103858</td>\n      <td>NaN</td>\n      <td>m</td>\n      <td>25/5/2018</td>\n      <td>15:40</td>\n      <td>e9</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>7185</th>\n      <td>e9m9</td>\n      <td>3.699470</td>\n      <td>NaN</td>\n      <td>m</td>\n      <td>25/5/2018</td>\n      <td>17:21</td>\n      <td>e9</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>7186</th>\n      <td>e9m9</td>\n      <td>1.766447</td>\n      <td>NaN</td>\n      <td>m</td>\n      <td>24/5/2018</td>\n      <td>16:26</td>\n      <td>e9</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>7187</th>\n      <td>e9m9</td>\n      <td>0.497900</td>\n      <td>1.169597</td>\n      <td>m</td>\n      <td>23/5/2018</td>\n      <td>12:30</td>\n      <td>e9</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>7188</th>\n      <td>e9m9</td>\n      <td>3.990179</td>\n      <td>1.146944</td>\n      <td>m</td>\n      <td>23/5/2018</td>\n      <td>13:44</td>\n      <td>e9</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n<p>7189 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "data = pd.read_csv('exercise1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we are going to do is to merge the Date and Hour columns.\n",
    "For this, we will concatenate the strings that contain the date and time\n",
    "and then transform them into a datetime object.\n",
    "\n",
    "We will then transform the result into a number\n",
    "(the number of days since a reference time point).\n",
    "Finally, we will remove the extra column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   ID_e         E         N Sex        Date Cell Label\n0  e1f1  5.583066  1.175189   f  125.518750   e1     o\n1  e1f1  5.325020  0.962680   f  171.430556   e1     o\n2  e1f1  3.412439  0.947501   f  171.600694   e1     o\n3  e1f1  3.761561  2.010046   f  171.520833   e1     o\n4  e1f1       NaN  1.144831   f  165.504167   e1     o",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_e</th>\n      <th>E</th>\n      <th>N</th>\n      <th>Sex</th>\n      <th>Date</th>\n      <th>Cell</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e1f1</td>\n      <td>5.583066</td>\n      <td>1.175189</td>\n      <td>f</td>\n      <td>125.518750</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e1f1</td>\n      <td>5.325020</td>\n      <td>0.962680</td>\n      <td>f</td>\n      <td>171.430556</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e1f1</td>\n      <td>3.412439</td>\n      <td>0.947501</td>\n      <td>f</td>\n      <td>171.600694</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e1f1</td>\n      <td>3.761561</td>\n      <td>2.010046</td>\n      <td>f</td>\n      <td>171.520833</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e1f1</td>\n      <td>NaN</td>\n      <td>1.144831</td>\n      <td>f</td>\n      <td>165.504167</td>\n      <td>e1</td>\n      <td>o</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'] + ' ' + data['Hour'])\n",
    "data = data.drop('Hour', axis=1)\n",
    "time0 = pd.Timestamp('2018-01-01 00:00:00')\n",
    "data['Date'] = (data['Date'] - time0) / pd.Timedelta(1, 'day')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now transform all categorical values into numerical ones.\n",
    "For the sex we will use just 0 and 1.\n",
    "For the column 'Cell', we could either use the number in the cell\n",
    "or convert the field using a one-hot-encoder.\n",
    "\n",
    "It's hard  to decide which option is best without having additional details\n",
    "about the data collection. For simplicity, we will just use the cell number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   ID_e         E         N  Sex        Date  Cell Label\n0  e1f1  5.583066  1.175189    0  125.518750     1     o\n1  e1f1  5.325020  0.962680    0  171.430556     1     o\n2  e1f1  3.412439  0.947501    0  171.600694     1     o\n3  e1f1  3.761561  2.010046    0  171.520833     1     o\n4  e1f1       NaN  1.144831    0  165.504167     1     o",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_e</th>\n      <th>E</th>\n      <th>N</th>\n      <th>Sex</th>\n      <th>Date</th>\n      <th>Cell</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e1f1</td>\n      <td>5.583066</td>\n      <td>1.175189</td>\n      <td>0</td>\n      <td>125.518750</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e1f1</td>\n      <td>5.325020</td>\n      <td>0.962680</td>\n      <td>0</td>\n      <td>171.430556</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e1f1</td>\n      <td>3.412439</td>\n      <td>0.947501</td>\n      <td>0</td>\n      <td>171.600694</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e1f1</td>\n      <td>3.761561</td>\n      <td>2.010046</td>\n      <td>0</td>\n      <td>171.520833</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e1f1</td>\n      <td>NaN</td>\n      <td>1.144831</td>\n      <td>0</td>\n      <td>165.504167</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup = {\"Sex\": {\"f\":0, \"m\":1},\n",
    "          \"Cell\": {\"e1\":1, \"e2\":2, \"e3\":3, \"e4\":4, \"e5\":5, \"e6\":6, \"e7\":7, \"e8\":8, \"e9\":9, \"e10\":10}\n",
    "          }\n",
    "data.replace(cleanup, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the data, we can see that the ID is just a concatenation of the cell,\n",
    "the sex and the lizard number.\n",
    "Because of this, there is a perfect mapping between the ID and the label.\n",
    "However, instead of removing it right away,\n",
    "we are going to use it to fill the missing values in E and N.\n",
    "\n",
    "We will first transform the ID into a numeric value using the method `factorize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      ID_e         E         N  Sex        Date  Cell Label\n0        0  5.583066  1.175189    0  125.518750     1     o\n1        0  5.325020  0.962680    0  171.430556     1     o\n2        0  3.412439  0.947501    0  171.600694     1     o\n3        0  3.761561  2.010046    0  171.520833     1     o\n4        0       NaN  1.144831    0  165.504167     1     o\n...    ...       ...       ...  ...         ...   ...   ...\n7184   179  1.103858       NaN    1  144.652778     9     y\n7185   179  3.699470       NaN    1  144.722917     9     y\n7186   179  1.766447       NaN    1  143.684722     9     y\n7187   179  0.497900  1.169597    1  142.520833     9     y\n7188   179  3.990179  1.146944    1  142.572222     9     y\n\n[7189 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_e</th>\n      <th>E</th>\n      <th>N</th>\n      <th>Sex</th>\n      <th>Date</th>\n      <th>Cell</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5.583066</td>\n      <td>1.175189</td>\n      <td>0</td>\n      <td>125.518750</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>5.325020</td>\n      <td>0.962680</td>\n      <td>0</td>\n      <td>171.430556</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>3.412439</td>\n      <td>0.947501</td>\n      <td>0</td>\n      <td>171.600694</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3.761561</td>\n      <td>2.010046</td>\n      <td>0</td>\n      <td>171.520833</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1.144831</td>\n      <td>0</td>\n      <td>165.504167</td>\n      <td>1</td>\n      <td>o</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7184</th>\n      <td>179</td>\n      <td>1.103858</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>144.652778</td>\n      <td>9</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>7185</th>\n      <td>179</td>\n      <td>3.699470</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>144.722917</td>\n      <td>9</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>7186</th>\n      <td>179</td>\n      <td>1.766447</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>143.684722</td>\n      <td>9</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>7187</th>\n      <td>179</td>\n      <td>0.497900</td>\n      <td>1.169597</td>\n      <td>1</td>\n      <td>142.520833</td>\n      <td>9</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>7188</th>\n      <td>179</td>\n      <td>3.990179</td>\n      <td>1.146944</td>\n      <td>1</td>\n      <td>142.572222</td>\n      <td>9</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n<p>7189 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ID_e'] = pd.factorize(data.ID_e)[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to change the label.\n",
    "We could use a one-hot encoder for this,\n",
    "as the label seems to be a categorical value with no ordinal relationship.\n",
    "However, most classifiers need a single output\n",
    "and treat multiclass problems as one vs. all approach,\n",
    "so using a one-hot encoder is not strictly required.\n",
    "\n",
    "A notable exception to this are artificial neural networks\n",
    "(so if we want to use ANN we would need to change the following lines\n",
    "to use a one-hot encoder).\n",
    "\n",
    "Most classifiers that deal with more than 2 classes tend to do the probability\n",
    "or something along those lines for what each thing is\n",
    "`[prob of A, prob of B, prob of C]`\n",
    "\n",
    "Decision trees and neural networks work well with more than 2 classes.\n",
    "Most other classifiers don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Label'] = pd.factorize(data.Label)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to transfer the data to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = data.loc[:, data.columns != 'Label'].to_numpy()\n",
    "y = data.loc[:, 'Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  0, 387, 390,   0,   0,   0])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(x),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "For the prediction we are going to use a Random Forest approach,\n",
    "which uses ensembles of decision trees.\n",
    "We are going to tune its main parameters: the number of trees and the maximum depth.\n",
    "\n",
    "For the imputation of the missing values we will use the average based on the ID.\n",
    "Considering that decision trees ignore the magnitude of the inputs,\n",
    "we will not use any normalisation or scaling.\n",
    "\n",
    "Also, we will remove the ID_e column as we know that it's a false predictor.\n",
    "\n",
    "Finally, as we know that the data is groupped by lizard,\n",
    "we will use cross validation with shuffling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now start by creating the imputer\n",
    "\n",
    "* Grouping by each lizard, finding the mean position for each lizard\n",
    "* If we find a missing value:\n",
    "    * If we've seen that lizard before\n",
    "        * We fill in its position to be the mean position for that lizard\n",
    "    * If we haven't seen that lizard before\n",
    "        * We fill in its position with the mean position for all lizards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# We need to create a pipeline module for our special imputation method\n",
    "class GroupImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, apply_to_columns, group_by_column):\n",
    "        self.apply_to_columns = apply_to_columns\n",
    "        self.group_by_column = group_by_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.global_mean = np.nanmean(X[:, self.apply_to_columns], axis=0)  # compute the global mean to be used as fallback method\n",
    "        groups = np.unique(X[:, self.group_by_column])  # get the groups in the set\n",
    "        self.group_means = {}\n",
    "        for group in groups:\n",
    "            selected = X[:, self.group_by_column] == group  # select rows belonging to the group 'group'\n",
    "            group_means = np.nanmean(X[np.ix_(selected, self.apply_to_columns)], axis=0)  # compute group means\n",
    "            group_means[np.isnan(group_means)] = self.global_mean[np.isnan(group_means)]  # if any mean is missing, use global mean\n",
    "            self.group_means[group] = group_means  # store for later use\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        nans = np.isnan(X[:, self.apply_to_columns])\n",
    "        if not np.any(nans):\n",
    "            return X  # return X unchanged if there are no missing values\n",
    "        X = np.copy(X)  # work on a copy of the data\n",
    "        groups = np.unique(X[:, self.group_by_column])  # get the groups in the set\n",
    "        for group in groups:\n",
    "            selected = X[:, self.group_by_column] == group  # select rows belonging to the group 'group'\n",
    "            group_means = self.group_means.get(group, self.global_mean)  # retrieve saved group means if any, otherwise use global mean\n",
    "            for j in range(len(self.apply_to_columns)):\n",
    "                X[np.logical_and(nans[:, j], selected), self.apply_to_columns[j]] = group_means[j]  # replace nans\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build the pipleline.\n",
    "Note that we need to remove the ID_e column as it's a false predictor.\n",
    "\n",
    "We then train the random forest classifier, tuning its parameters using a grid search.\n",
    "\n",
    "Note that we are not calling to individual methods for `fit` and `predict`,\n",
    "everything is performed through the `cross_validate` method.\n",
    "\n",
    "We use `ColumnTransformer` to drop the ID_e column without any problems.\n",
    "\n",
    "`pipe` is the pipeline we're using. Sums up the full pipeline stuff in a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as mt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "\n",
    "\n",
    "cv = KFold(shuffle=True) # perform CV after shuffling the data\n",
    "# SHOULD ALWAYS SHUFFLE THE DATA IF WE ALREADY KNOW STUFF ABOUT THE DATA!\n",
    "# but may not always be a good idea, such as if we're using 'leave one out' validation\n",
    "# (where we train using all but one of the lizards, then test on the other lizard)\n",
    "\n",
    "imputer = GroupImputer(apply_to_columns=[1, 2], group_by_column=0)\n",
    "# impute cols 1 and 2 using groups in col 0\n",
    "\n",
    "dropper = ColumnTransformer([('dropper', 'drop', 0)], remainder='passthrough')\n",
    "# drop column 0 (ID_e) and leave others unchanged\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# We're using the RandomForestClassifier for classification\n",
    "\n",
    "pipe = Pipeline([('imputer', imputer), ('dropper', dropper), ('rf', rf)])\n",
    "# build pipeline\n",
    "# as far as sklearn cares, this pipeline is a classifier.\n",
    "\n",
    "# input data -> imputer -> dropper -> rf -> classified data\n",
    "\n",
    "param_grid = {\n",
    "    'rf__n_estimators': np.arange(3, 51, 6), # test forests of different sizes\n",
    "    'rf__max_depth': [3, 5, 10, 20]          # test different values for max_depth\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "And here we cross-validate stuff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "scores = cross_validate(search, x, y, scoring=['accuracy'], cv=cv, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the results for 5 folds for each configuration of the classifer.\n",
    "\n",
    "\n",
    "With the results,\n",
    "we can explore the parameters to know the best combination of\n",
    "number of trees and maximum depth.\n",
    "\n",
    "We can do this on all data since this is only done for information purposes,\n",
    "not for model selection (which is done in nested CV by `GridSearchCV`).\n",
    "\n",
    "Since we performed a five-fold validations, we have five values for each combination,\n",
    "so we need to calculate the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANsAAAEGCAYAAADsVOAFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAActklEQVR4nO2debScVZmvn18mEhIjIOhiEhBxQAT0RqBxuIKgtNA4XLFR6VbbK+oFjaC2Q6tA2+gSUcThqlEUlMGGgDaNE1wE0W4bTCAgIbSoaDcoQ1Q0IENyzu/+sXedVE7qVO1zTn3fqeF91tqrqnZ9e++3DnnZ0zvINkEQVM+smRYgCIaFULYgqIlQtiCoiVC2IKiJULYgqIk5My1ACbMXLvScbbapZaz5azfUMg6A586ubSyA9VuqtrEeuvuOtba3m2r7Fx200L/7/UjRsytvevh7tg+b6lh10RfKNmebbdhp6Qm1jLXHWffWMg7AIzssrm0sgLuXzK9trFtOO/HX02m/9vcjXPu9nYqenbv9L7adzlh10RfKFgwjZsSjMy1EVwllC3oSA6MMlsFFKFvQs4wSM1sQVI4x62MZGQTVY2AklpFBUA+xZwuCGjAwMmAeKaFsQc8yWDu2ULagRzEeuD1b5baRkmZLukHSZfnz2ZJul7Qql32rliHoP2xYX1j6hTpmtqXAGqDZNuldtpfXMHbQt4gR6rPlrINKZzZJOwGHA1+qcpxg8DAw6rLSL1S9jPwk8Pdsvtc9VdJNks6QtEWrhpKOlbRC0orR+x+oWMygFxnJs1un0i9UpmySjgDusb1y3FfvBZ4CPAvYBnh3q/a2l9leYnvJrEULqxIz6FHSpfZgKVuVe7ZnA0dKejEwH1gs6Vzbx+TvH5b0FeCdFcoQ9CkG1nuwfJsr+zW232t7J9u7AkcD37d9jKTtASQJeClwc1UyBP2LESPMKir9wkzcs50naTtAwCrgzTMgQ9AHjLp/logl1KJstq8Grs7vD65jzKC/aezZBomwIAl6FDEyYHu2ULagJ0me2qFsQVA5tnjE9UYfq5pQtqBnGY09WxBUTzogiWVkENTA4B2QDNavCQaGxgFJSSlB0mGS/lPSzyW9p8X3b5b00+z29SNJe477/vGS7pf0zqa6EyStlnSzpAsktY2C2xcz27w/mZ2+X09Y8Pue0RfBdafEojv7y/d5pEuX2pJmA58FDgXuAH4i6VLbtzQ9dr7tz+fnjwQ+ATSHNP8E8J2mPncE3gbsaftBSReSLKXOnkiOvlC2YPgwYr279s9zP+Dntn8JIOnrwEuAMWWz/aem5xfCRjdxSS8FbgfGu5/MARZIWg9sCfymnRChbEFPMskDkm0lrWj6vMz2sqbPOwL/3fT5DmD/8Z1IOg44EZgHHJzrFpE8Uw6lyWje9p2STgf+C3gQuNz25e2EjD1b0JMYMeKyAqxtuGPlsqxT/y3HtD9re3eScr0/V58MnGH7/uZnJW1Nmh13A3YAFko6hjbEzBb0LF20ILkT2Lnp8065biK+Dnwuv98feIWk04CtgFFJDwF3A7fbvhdA0iXAgcC5E3Uayhb0JDbdPPr/CbCHpN1ISnY08OrmByTtYfu2/PFw4LYkh5/b9MzJwP22PyNpf+AASVuSlpEvAJqXspsRyhb0JOmApDvmWrY3SDoe+B4wG/iy7dWS/hFYYftS4HhJhwDrgT8Ar+3Q57WSlgPXAxuAG4C2y9dQtqBn6aYFie1vA98eV/fBpvdLC/o4edznk4CTSmUIZQt6EqNwHg2CugjbyCCogRQ3crCUrcpQdvMlXSfpxmw/dkquP1jS9dme7BxJofBBC8rC2PVT6IQq/9fxMHCw7X2AfYHDJB0InAMcbXsv4Nd0OPUJhpMUym52UekXqgxl56Zb97m5jACP2P5Zrr8C+F9VyRD0L7YY9ayi0i9UHet/tqRVwD0kxboOmCNpSX7kFWx6s9/cdiz8+PpHIvz4MDLiWUWlX6hUUtsjtvclmcfsBzyNdHt/hqTrgHWk2a5V27Hw43PnRfjxYSP5s6mo9At1xY28T9JVwGG2TweeCyDphcCT6pAh6DfCU7sYSdtJ2iq/X0ByUbhV0mNz3RYk6+rPVyVD0L+ko38VlX6hyplte+Cc7CU7C7jQ9mWSPpYz3MwCPmf7+xXKEPQp3bSN7BUqUzbbNwHPaFH/LuBdVY0bDA4RpDUIaiC52PTPErGEULagZ+mn/VgJoWxBT5Ks/mMZGQSVM4iZR0PZgh4lZrYgqI1+sg4pIZQt6EniNDIIaiSWkTPAhgVi7V5zaxlriz+680Nd4ndL6slf0GC3i/on1v9QxiCRtDtwh+2HJT0f2Bv4qu37qhUtGGYMbBiwma3k11wMjEh6Iiku3s7A+ZVKFQQwcM6jJcvI0Rzk8mXAp21/WtINVQsWDDl9ZtFfQomyrZf0KlKskL/KdfVsoIKhpeE8OkiUzMGvB/4CONX27Tle+teqFSsIhsyfLfui/YPt1zTqbN8OfLRqwYLhpuE8Oki0ndlsjwC7SJpXkzxBAKSj/w2js4pKCRXl1N5K0nJJt0paI+kv2slQsmf7JfBvki6lKc2p7U8UtA2CKdOtPVsVObUzZwLftf2KPCFt2U6OEmX7RS6zgEcVPB8E08ddXUZ2Pae2pEcDzwNel9s/AjzSToiOyma7ETZ8Uf58f/sWY8LMB64BtsjjLLd9kqSzgCWAgJ8BryvtMxgeJrlnqz2nNim9773AVyTtA6wEltqeMMhpxwWvpL3yvdpqYLWklZKe1qkdrcOPHwCcYHsf23uTkn8fX9BXMIRM4jSy9pzapAnkmaSgVc8gzXqb7QXHN+jEMuBE21cBZJOtL5LyB7cT3MD48ONuTNeSBCygaboOggZGjBQefhRQRU7t5SQzxmvzc8vpoGwlv2ZhQ9EAbF9NWtN2ZHz48YZgkr4C3AU8Bfj0BG3Hwo+PPBjhx4eRLkZEHsupnQ8yjgYubX5A0h5NHzfJqW17V9u7Ap8EPmz7M7bvAv5b0pNzmxfQtAdsRYmy/VLSByTtmsv7SSeUHRkfflzSXrn+9cAOwBrgrydoOxZ+fPaCCD8+bNjdu9S2vYG0Xfke6d/chY2c2vnkEVJO7dV5cjiRsuxKbwXOk3QTaav04XYPlywj/w44BbiEtOT7IcmqpJjm8OPAzbluJJ8K/T3wlcn0FwwH7uKldkU5tVeRDvuKKFG2Q2y/rblC0lHARe0aSdoOWJ8VrRF+/DRJT7T987xnOxK4tVTYYJjoL1OsEkqU7b1srlit6sazWfhx4FvADyUtJh393wi8ZVISB0NDN2e2XmBCZZP0l8CLgR0lfarpq8VARxfjicKPA8+erJDB8GHDyOiQKBvwG2AFaam3sql+HXBClUIFAQyei82Eymb7RuBGSefbXl+jTEGAGaJlZBO7SvoIsCcwv1Fp+wmVSRUEA3hAUnLP9hXSbfoG4CDgq8C5VQoVBJD2bSWlXyhRtgW2rwRk+9f5ruHwasUKgrSMLCn9Qsky8mFJs4DbJB1PsilbVK1YwbCTTiP7J3JWCSW/ZinJKe5twP8A/oYyU5YgmBaDtows8Wf7SX57P5M00wqC6dBPS8QSSiIiLwH+Adil+fnsj1YLc+9+gB1O//daxho56Jm1jAMwMnd+54e6yB3/u0Yf3Sum19z0136shJI923mkhPM/BfonWHzQ9/TRCrGIEmW71/alnR8Lgi5i8BCZazU4SdKXgCtJoQ4AsH1JZVIFAUO4ZyMdijyFFNagsYw0yb8tCCqjn04aSyhRtmfZfnLnx4KgewyibWTJPdu/j48OGwSVY8AqK31Cycx2ALBK0u2kPZtIUbJqO/oPhpNhXEYe1vmRIOg2Gp7TSEmLc4zHdTXKEwQbGaKZ7XzgCJKXtmETt1kDbf3ZJO1Mcsd5XH5+me0zJf0z0Dhw2Qq4L4e7C4KNePAOSNp5ah+RX3ebYt8bgHfYvl7So4CVkq6wPRYnUtLHgT9Osf9g0Bmwma0k1v+VJXXjsf1b29fn9+tIwTF3bOpDwCuBCyYjcDBMqLD0B+32bPNJrjXbStqajb9qMU1KU4KkXUmRtq5tqn4ucLft2yZocyxwLMD89mmvgkFlwCxx2+3Z3gS8nRQmfCUble1PwGdKB8gpdy4G3j4uB9araDOr5UwkywAWa5sBW1AEHWncsw0Q7fZsZwJnSnqr7ZbJLzohaS5J0c5rtqWUNAd4OckZNQhaMmj3bCUWJHflAw4kvV/SJZI6On3lPdlZwJoWKYEPAW61fcekJQ6GBxeWPqFE2T5ge52k55CU5Cw25q5qx7NJIRQOzknBV0l6cf7uaOJgJOhEF821qkhgn+tnS7pB0mWdZCixIBnJr4eT7sq+JemfOjWy/SMmOCqy/bqCcYMhR12atSpMYA8pRs8a0sFhW0pmtjslfYGUR+3bkrYobBcEU8eC0cLSmbEE9jnRfCOB/cbhyhLYr25uI2kn0iT0pRIhSpTmlaQkci+yfR+wDSlMQhBUS/mebdtGltpcjh3XU6sE9ptdX0k6TtIvgNNI0eSaE9if0kLCT5LyCxZdUnRUNtt/JqXpfU6u2kBOgRoElVKubLUnsJd0BHCP7ZUUUhJd6yRSdsUnk0KRzyWFH4/UT0G1dO+ksYoE9jsCR+ZDv/nAYknn2j5mok5LDkheRrL+aJhe/aZxFRAEldHdS+2xBPYkJTsaeHXzA5L2aLJm2iSBfdMzJwP3224Ydbw31z8feGc7RYMyZXvEtqV0NiQpsskHtdCt00jbG3Lo/O8Bs4EvNxLYAyty9LjjJR0CrAf+QAVRv0uU7cJ8GrmVpDeSEtp/sduCBMFmdPHCuooE9k31VwNXd2pfEn78dEmHkmwinwx80PY0490GQWe6NbP1CiUzG1m5ZkzBHnnCAm7/SD0hT+atqi8k+M7f+UNtYwGsfWirWsebNsNiiBwEM0qf2T2WEMoW9C4DpmwTXmo3vLElfbQ+cYJgIxotK/1Cu5lte0kHki7uvs44o+JGyIMgqIwBm9naKdsHgQ+QbtvH+6MZOLgqoYJAHqLTSNvLgeWSPmD7QzXKFASJYTuNtP2h7N/zvFx1te2OjnJBMG2GZWZrIOkjJH+g83LVUkkH2n5fpZIFQ8/QLCObOBzY1/YogKRzgBuAULagOtxfJ40llHpcb9X0/tEVyBEEmzOEAX8+Atwg6ew8q60ETu3USNLOkq6SdIuk1ZKW5vqj8udRSUumJ34w0AyYspUckFwg6WrgWbnq3bbvKui7Zax/4GZSzMgvTFHmYEgYxj0btn8LXDqZjnOb3+b36yStAXZseAyksJJBMDzUYhs5Qaz/Tm3GYv3P2Ta2iUPJgM1slYekaxPrvy22lzUCuMxeHM7hQ4cHzzayrbLlaK+3TrXziWL9B0ERA3ZA0lbZbI8A/ynp8ZPtuEOs/yBoi9hoH9mp9Asle7atgdWSrgMeaFTaPrJDu0as/59KWpXr3gdsAXwa2A74lqRVtl80WcGDIaCPFKmEEmX7wFQ6bhfrH/jGVPoMhog+m7VKKLln+4GkXYA9bP8/SVuSwoEFQbX00eFHCSU5td8ILGfjJfSOwDcrlCkIgMHbs5Uc/R9H2n/9CSBHjX1slUIFATBwp5Ele7aHbT/SsPjIKXr76CcGfUmfKVIJJTPbDyS9D1iQg7VeBPxrtWIFwXAuI98D3Av8FHgTKYTz+9u2CIJuMGDLyJL8bKPAOcCHSAnhzrHdRz8x6Fe6aa7V7ZzaE7mQtaMkLMLhwOeBX5DuzXaT9CbbrfILV8IWd2xgj3f9vpaxvnXtV2sZB+BJ+3Q9UUpbFv6wjzwtujhrVZRTu6UL2bg+N6HkgOTjwEG2f54F2R34Fq2TeQdBVxATW0RMgbGc2gA5DupLgDHFKMyp3WxB1dKFrLnP8ZQo27qGomV+CawraBcE06N7m5VWObX3H/+QpOOAE4F55LioTTm1DwXe2arzUheyCZVN0svz2xWSvg1cSPr5R5EyOQZBpUzipHFbSSuaPi+bSl5t258FPivp1aRDwNfSlFO7lcPzZFzI2s1sf9X0/m7gf+b39wILSn9AEEyZcmVba7tdPJuu59S2/ZnJupC1i4j8+k6Ng6AyuhvKrus5tafiQlZyGrkb8FZg1+bnC1xsgmB69HZO7ZYuZDmdcEtKDki+SdLgf2Xg7LCDXqab1iHdzqndwYWsJSXK9pDtT02m0yDoCgNmOlGibGdKOgm4HHi4URn52YKq6Se7xxJKlO3ppLXpwWxcRkZ+tqBazMBtWkqU7SjgCbYfmUzHkr4MHAHcY3uvXHcy8EbS9QF02FAGw0sj4M8gUWL1fzObJtYo5Ww2tS1rcIbtfXMJRQsmZsCs/ktmtq2AWyX9hE33bG2P/m1fk81YgmBKaMCcS0qU7aQuj3m8pL8FVpCspv/Q6qHm8OPzZz+qyyIEPU+fzVolFEXX6uJ4nyP5xTm/fhz4uwnGXQYsA3j0Fo8bsD97UMKg7dlKLEjWsfH/MfOAucADthdPdjDbdzf1+0UgcnMHE9JPcfxLKJnZxtZw2R7sJcABUxlM0vbZDwjgZaTDlyBozYDNbJPKYuPEN4GO4cIlXQD8GHiypDskvQE4Lbue3wQcBJwwBZmDYaAw2E8/LTVLlpEvb/o4C1gCPNSpne1Xtag+q1y0YOjpI0UqoeQ0stmvbQPwK9JSMggqYxAvtUv2bOHXFswIGh0sbWsXFuGDE31H2r59qAJ5giAxZPdsD7SoWwi8AXgM6Z4sCCpjaI7+bX+88T7HxVsKvJ4Un+HjE7ULgq4xRDMbkrYhhfZ6DSkq8jMnMq8Kgm4zNAckkj4GvJxkMvV02/fXJlUQGBgwQ+R2l9rvAHYgxc/7jaQ/5bJOUtv4eEHQDboZ678XaLdnm5R1SZVsWDSP3z1vp1rG2uPct9QyDsA2NRurPfq2VmdevclQ3rMFwYxgD9wyMpQt6FliZguCughlC4J6iJktCOrAwMhgaVsoW9CzxMwWBHUxYKeRPXOXFgTj6aandrcT2Jf0OZ5QtqA3KQ3QWqBsTQns/xLYE3jVeGUiJbB/uu19gdNICeub2SSBfWGfmzAjyiZpqaSbJa2W9PaZkCHobQRoxEWlgLEE9jmMfiOB/RiFCexXT6bP8dSubJL2IsX73w/YBzhC0hPrliPofWQXFXJO7aZy7LiuWiWw33Gz8aTjJP2CNLO9Ldc1EtifMpU+m5mJme2pwLW2/2x7A/ADkndBEGxkcsvItbaXNJVJJ6+HlMDe9u4k5Xp/rj6ZnMB+6j8mMROnkTcDp0p6DPAg8GJSKPJNaA4/Pm/h1rUKGPQCXbWN7HoCe2DlJPusX9lsr5H0UVJyxQeAVcBIi+fGwo8vfMzOg3UGHBTRxXu2KhLYz+nU53hm5J7N9lnkGJKSPkxa7wbBpnRpZqsigf1EfbZrMyPKJumxtu+R9HjSfm1K4cyDAcaUnjSWddflBPYT9dmOmbIguTjv2dYDx9m+b4bkCHqZAds8zNQy8rmdnwqGnWFMhhgEM0MoWxDUgIE+CuZTQihb0JMIxzIyCGpjdLCmtlC2oDeJZWQQ1EcsI4OgLkLZgqAOIkjrjLDgsQ/ytLfWE6v7uov3rmUcgEV3PlzbWAAPbj+/1vGmRUTXCoL6iD1bENRFKFsQ1ICBYUlgHwQzSxyQBEF9hLIFQQ0YGBksE5JQtqBHMTiULQjqIZaRQVADcRo5fSTNB64BtsjjL7d9Ut1yBH1AzGzT5mHgYNv3S5oL/EjSd2z/xwzIEvQyoWzTw7aBRijnubkM1l81mD42jGwWu7evmaksNrMlrQLuAa6wfW2LZ45tJEp46L6Hapcx6AHsstInzIiy2R7JebB2AvbLmW3GP7OskShh/lZ9ZK0edI9Qtu6Rg7NeBRw2k3IEvYjTaWRJ6RNmIj/bdpK2yu8XAIcCt9YtR9DjGOzRotIvzMRp5PbAOTlN6izgQtuXzYAcQa8zYOZatc9stm+y/Qzbe9vey/Y/1i1D0AfYKZRdSSlgqgnsJe2X61ZJulHSy5ranJBTVd8s6YJ8hzwhkcA+6F26dEAyzQT2NwNLcv1hwBckzZG0IykV8BLbe5HSRh3dTo4w1wp6FncvSOtYsnkASY1k87eMjTVBAnvbf26qn9+oz8wBFkhaD2wJ/KadEKFsQY8yqWP9bSU1p4peNi6vdqtk8/uP70TSccCJwDzg4Kb6/YEvA7sAf5Nzwd8p6XTgv0jpqi+3fXk7IWMZGfQmDUPksqP/KhPYY/ta208DngW8V9J8SVuTZsfdgB2AhZKOadd/KFvQkxjwyEhRKWAqCexfuplM9hqSqeFewCHA7bbvtb0euAQ4sJ0QoWxBb+LsPFpSOjOWwF7SPNJBxqXND0jao+njWAL73GZOfr8L8BTgV6Tl4wGStpQk4AXAmnZCxJ4t6FncJeuQaSawfw7wnnwIMgr8H9trgbWSlgPXAxuAG4C2y9dQtqB36aJ1yFQT2Nv+GvC1Cb47CSj2xZT7wJBT0r3Ar6fQdFtgbZfFibHK2MX2dlMdVNJ389glrLXd8/a1faFsU0XSCttLYqz+GGvQiQOSIKiJULYgqIlBV7YpXW7GWDM21kAz0Hu2IOglBn1mC4KeIZQtCGpi4JQtG4lelx39Vks6peLxftXkdLiic4tJ9/9lSfdIurmpbhtJV0i6Lb9u3aWxdpZ0laRb8t9uaZXjDRsDp2xsDAK7D7AvcJikAyoe8yDb+1Z0H3U2mwdEeg9wpe09gCvz526wAXiH7T2BA4DjspNlVeMNFQOnbE4MTBBY29cAvx9X/RLgnPz+HFpYqE9xrN/avj6/X0cyrN2xqvGGjYFTNigLAttFDFwuaaWkYyscp5nH2f5tfn8X8LhuDyBpV+AZwLV1jDcMDKSylQSB7SLPsf1MUnyL4yQ9r8KxNiOHc+/qzC1pEXAx8PZx4QIqGW9YGEhla1BHEFjbd+bXe4BvkOJdVM3dkrYHyK/3dKvjnOzkYuA825dUPd4wMXDKVmcQWEkLJT2q8R54ISkaU9VcykZ/q9cC/9KNTrMT5FnAGtufaPqqkvGGjYGzIJG0N2kT3xwEtpLYlJKeQJrNIPkGnm/71C6PcQHwfJK7yd0k/6lvAhcCjye5Hr3S9vhDlKmM9Rzgh8BPSY6SAO8j7du6Pt6wMXDKFgS9ysAtI4OgVwllC4KaCGULgpoIZQuCmghlC4KaCGVrgaTHNKUJukvSnU2f51Uw3tWSpmTELOmlzRlZptNXUC0RN7IFtn9H8hhA0snA/bZPb3wvaU5OrtALvBS4jKaMLEFvEjNbIZLOlvR5SdcCp0naXdJ3swHyDyU9JT+3naSLJf0kl2e36GuBpK9LWiPpG8CCpu9eKOnHkq6XdFG2U2z4zZ2Wfeeuk/RESQcCRwIfy7Pu7rmbo/IzP5P03Mr/OEERMbNNjp2AA22PSLoSeLPt25RSCv1fUpqhM4EzbP9I0uNJIa+fOq6ftwB/tv3UbPFyPYCkbUnZUw6x/YCkd5NSGDUsYP5o++mS/hb4pO0jJF0KXGZ7ee4DYI7t/SS9mGRxckhVf5CgnFC2yXFRVrRFpIwlF+V/3ABb5NdDgD2b6hdLWtTkYwfwPOBTkNIeS7op1x9Ayoz5b7n9PODHTe0uaHo9o42cDQPilcCuxb8uqJRQtsnxQH6dBdyX3XjGMws4wPZDU+hfJP+7V03wvSd4P56H8+sI8d+4Z4g92xTIPl63SzoKkrW8pH3y15cDb208K2nfFl1cA7w6f78XsHeu/w/g2ZKemL9bKOlJTe3+uum1MeOtAx413d8UVE8o29R5DfAGSTcCq0mhAyAnNZd0k6RbgDe3aPs5YJGkNaT92EoA2/cCrwMuyEvLH5PygTXYOtcvBU7IdV8H3iXphqYDkqAHCav/PkHSr4AlOTdY0IfEzBYENREzWxDURMxsQVAToWxBUBOhbEFQE6FsQVAToWxBUBP/HzqytvtObfihAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "features = np.zeros((len(param_grid['rf__n_estimators']), len(param_grid['rf__max_depth'])))\n",
    "for estimator in scores['estimator']:\n",
    "    features += estimator.cv_results_['mean_test_score'].reshape(features.shape)\n",
    "features /= len(scores['estimator'])\n",
    "\n",
    "im = plt.imshow(features, origin='lower')\n",
    "plt.colorbar(im)\n",
    "plt.xticks(np.arange(len(param_grid['rf__max_depth'])), param_grid['rf__max_depth'])\n",
    "plt.yticks(np.arange(len(param_grid['rf__n_estimators'])), param_grid['rf__n_estimators'])\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.ylabel(\"Number of estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "No meaningful difference between these classifiers,\n",
    "but all equally bad -> all equally good."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall performance\n",
    "Finally, we can look at the overall performance of our pipeline.\n",
    "The scores across all (outer) CV folds and its average are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy [0.3922114  0.3852573  0.4054242  0.42767733 0.46555324]\n",
      "Average accuracy 0.41522469446952825\n"
     ]
    }
   ],
   "source": [
    "print('Fold accuracy', scores['test_accuracy'])\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV approach shown above shuffles all data before building the different folds.\n",
    "Therefore some observations of the same lizard may end up in the training set and\n",
    "some in the test set.\n",
    "Is this OK? Yes and no.\n",
    "It depends on the real-life situation that the CV is supposed to be a proxy for.\n",
    "This CV scheme is fine if we intend to use our system to identify the color of a\n",
    "lizard that we observe at a given time in a given place, assuming that we may have\n",
    "already observed that same lizard.\n",
    "\n",
    "What if we want to build a system that tries to predict the color of a new\n",
    "lizard never observed before? In this case we need to create our folds making\n",
    "sure that each lizard's data is never split between different folds.\n",
    "\n",
    "We can do this using [`GroupKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html)\n",
    "and passing the `groups` argument to `cross_validate`.\n",
    "This time we won't be able to impute based on the lizard ID\n",
    "(because each test-fold lizard ID will not be present in the corresponding training set)\n",
    "but we could use the cell number instead.\n",
    "Also, for simplicity we will not use the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "group = x[:, 0]\n",
    "# the column 0 is our group (i.e. each lizard's ID)\n",
    "\n",
    "cv = GroupKFold(n_splits=3)\n",
    "# split into into 3 groups\n",
    "\n",
    "imputer = GroupImputer(apply_to_columns=[1, 2], group_by_column=5)\n",
    "# use column 5 (cell) to impute missing coordinates\n",
    "\n",
    "dropper = ColumnTransformer([('dropper', 'drop', 0)], remainder='passthrough')\n",
    "# drop column 0 (ID) and leave others unchanged\n",
    "\n",
    "scl = StandardScaler()\n",
    "rf = RandomForestClassifier()\n",
    "pipe = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('dropper', dropper),\n",
    "    ('scaler', scl),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "scores = cross_validate(\n",
    "    pipe, x, y,\n",
    "    scoring=['accuracy'],\n",
    "    cv=cv,\n",
    "    groups=group,\n",
    "    return_estimator=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that indeed `GroupKFold` splits the data\n",
    "so that each lizard's data is either completely in the training folds or in the test fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lizard IDs in training set\n",
      " [  0.   4.   5.   6.   7.   8.  10.  11.  14.  15.  16.  17.  19.  20.\n",
      "  22.  23.  24.  25.  26.  27.  30.  31.  32.  34.  35.  36.  43.  44.\n",
      "  46.  49.  50.  51.  53.  54.  55.  56.  57.  62.  64.  65.  66.  67.\n",
      "  68.  69.  70.  71.  72.  73.  76.  77.  78.  79.  80.  82.  83.  84.\n",
      "  88.  89.  90.  91.  93.  96.  97.  99. 100. 102. 103. 104. 105. 106.\n",
      " 107. 108. 110. 111. 112. 113. 115. 116. 117. 118. 121. 123. 124. 127.\n",
      " 130. 131. 132. 133. 134. 135. 141. 142. 143. 144. 145. 148. 150. 151.\n",
      " 152. 153. 154. 156. 157. 158. 159. 160. 161. 164. 166. 167. 168. 169.\n",
      " 170. 172. 173. 174. 175. 177. 178. 179.]\n",
      "Lizard IDs in test set\n",
      " [  1.   2.   3.   9.  12.  13.  18.  21.  28.  29.  33.  37.  38.  39.\n",
      "  40.  41.  42.  45.  47.  48.  52.  58.  59.  60.  61.  63.  74.  75.\n",
      "  81.  85.  86.  87.  92.  94.  95.  98. 101. 109. 114. 119. 120. 122.\n",
      " 125. 126. 128. 129. 136. 137. 138. 139. 140. 146. 147. 149. 155. 162.\n",
      " 163. 165. 171. 176.]\n",
      "---\n",
      "Lizard IDs in training set\n",
      " [  0.   1.   2.   3.   5.   8.   9.  10.  11.  12.  13.  14.  15.  16.\n",
      "  17.  18.  19.  21.  23.  24.  26.  28.  29.  31.  32.  33.  37.  38.\n",
      "  39.  40.  41.  42.  43.  45.  47.  48.  49.  50.  51.  52.  53.  55.\n",
      "  58.  59.  60.  61.  62.  63.  64.  66.  71.  72.  74.  75.  77.  79.\n",
      "  81.  83.  85.  86.  87.  88.  89.  91.  92.  94.  95.  96.  97.  98.\n",
      " 101. 103. 104. 108. 109. 110. 113. 114. 115. 116. 118. 119. 120. 122.\n",
      " 123. 125. 126. 127. 128. 129. 132. 136. 137. 138. 139. 140. 142. 143.\n",
      " 144. 146. 147. 149. 153. 155. 158. 159. 160. 162. 163. 165. 166. 168.\n",
      " 169. 171. 173. 174. 175. 176. 177. 179.]\n",
      "Lizard IDs in test set\n",
      " [  4.   6.   7.  20.  22.  25.  27.  30.  34.  35.  36.  44.  46.  54.\n",
      "  56.  57.  65.  67.  68.  69.  70.  73.  76.  78.  80.  82.  84.  90.\n",
      "  93.  99. 100. 102. 105. 106. 107. 111. 112. 117. 121. 124. 130. 131.\n",
      " 133. 134. 135. 141. 145. 148. 150. 151. 152. 154. 156. 157. 161. 164.\n",
      " 167. 170. 172. 178.]\n",
      "---\n",
      "Lizard IDs in training set\n",
      " [  1.   2.   3.   4.   6.   7.   9.  12.  13.  18.  20.  21.  22.  25.\n",
      "  27.  28.  29.  30.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.\n",
      "  44.  45.  46.  47.  48.  52.  54.  56.  57.  58.  59.  60.  61.  63.\n",
      "  65.  67.  68.  69.  70.  73.  74.  75.  76.  78.  80.  81.  82.  84.\n",
      "  85.  86.  87.  90.  92.  93.  94.  95.  98.  99. 100. 101. 102. 105.\n",
      " 106. 107. 109. 111. 112. 114. 117. 119. 120. 121. 122. 124. 125. 126.\n",
      " 128. 129. 130. 131. 133. 134. 135. 136. 137. 138. 139. 140. 141. 145.\n",
      " 146. 147. 148. 149. 150. 151. 152. 154. 155. 156. 157. 161. 162. 163.\n",
      " 164. 165. 167. 170. 171. 172. 176. 178.]\n",
      "Lizard IDs in test set\n",
      " [  0.   5.   8.  10.  11.  14.  15.  16.  17.  19.  23.  24.  26.  31.\n",
      "  32.  43.  49.  50.  51.  53.  55.  62.  64.  66.  71.  72.  77.  79.\n",
      "  83.  88.  89.  91.  96.  97. 103. 104. 108. 110. 113. 115. 116. 118.\n",
      " 123. 127. 132. 142. 143. 144. 153. 158. 159. 160. 166. 168. 169. 173.\n",
      " 174. 175. 177. 179.]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for train, test in cv.split(x, groups=group):\n",
    "    print('Lizard IDs in training set\\n', np.unique(x[train, 0]))\n",
    "    print('Lizard IDs in test set\\n', np.unique(x[test, 0]))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can look at the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy [0.21693784 0.22412354 0.24207012]\n",
      "Average accuracy 0.22771049835295418\n"
     ]
    }
   ],
   "source": [
    "print('Fold accuracy', scores['test_accuracy'])\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the performance is quite poor. Let's have a look at the confusion matrix\n",
    "\n",
    "For each class, how many times did we predict that it was each class?\n",
    "\n",
    "Columns: predicted values\n",
    "\n",
    "Rows: real value\n",
    "\n",
    "```\n",
    "       | A out | B out | C out\n",
    "------ | ----- | ----- | -----\n",
    "real A | Right | Wrong | Wrong\n",
    "real B | Wrong | Right | Wrong\n",
    "real C | Wrong | Wrong | Right\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[642, 863, 970],\n       [927, 423, 885],\n       [975, 932, 572]], dtype=int64)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = cross_val_predict(pipe, x, y, cv=cv, groups=group)\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our performace is worse than random.\n",
    "It's interesting how the correct class is always the one that is predicted least often\n",
    "(i.e. the diagonal is smaller than the other values).\n",
    "\n",
    "Is this an artifact of our algorithm,\n",
    "of the experimental design,\n",
    "or maybe lizards of the same colour tend to stay away from each other?\n",
    "\n",
    "Answering this very interesting question is beyond the scope of this notebook ;-)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Info for the assignment:\n",
    "* If stuff is being printed, explain why it's being printed.\n",
    "* Make some nice matplotlib graphs!\n",
    "    * Proper axes, proper size, proper colours, etc.\n",
    "    * takes time, but looks nice.\n",
    "    * Try not to use too many colours!\n",
    "        * Try using shapes for data points I guess to make it look legit\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}